 flume-agent.conf: |
    odlSAdxRR.sources = sAdxRRSource
    odlSAdxRR.sinks = sAdxRRSink
    odlSAdxRR.channels = sAdxRRChannel

    # Describe/configure the source
    odlSAdxRR.sources.sAdxRRSource.type = org.apache.flume.source.kafka.KafkaSource
    odlSAdxRR.sources.sAdxRRSource.kafka.bootstrap.servers = 10.202.xxx:9092
    odlSAdxRR.sources.sAdxRRSource.kafka.topics = s-adx-rr
    odlSAdxRR.sources.sAdxRRSource.kafka.consumer.group.id = odlConsumer-adx-rr
    odlSAdxRR.sources.sAdxRRSource.kafka.consumer.max.poll.records = 200
    # batchSize is the maximum number of messages written to Channel in one batch
    odlSAdxRR.sources.sAdxRRSource.batchSize = 1000
    odlSAdxRR.sources.sAdxRRSource.batchDurationMillis = 1000
    odlSAdxRR.sources.sAdxRRSource.kafka.consumer.auto.offset.reset = latest

    # interceptor
    odlSAdxRR.sources.sAdxRRSource.interceptors = CustomPathInterceptor
    odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.type = com.tecdo.oam.flume.interceptor.CustomPathInterceptor$Builder
    #存放到obs的目录格式，java中的时间格式，其中需要用单引号包裹固定字符串，并且需要使用\'进行转义，否则会无法正常生成目录
    odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.pathFormat = '\'year\'=yyyy/\'month\'=MM/\'day\'=dd/\'hour\'=HH'
    #生成路径的时间所属时区，会先把时间转成timestamp，再按时区格式化，用GMT不要用UTC
    odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.pathFormatTimeZone = GMT
    #时间字段取body的哪个字段，默认取body中的timestamp
    odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.datetimeKey = timestamp
    #上面取的datetimeKey是否是时间戳格式，默认为true
    odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.datetimeIsTimestamp = true
    #如果datetimeKey不是时间戳格式，则需要指明这个字段的时间格式，以及所属时区，用GMT不要用UTC
    #odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.datetimeFormat = yyyy-MM-dd HH:mm:ss
    #odlSAdxRR.sources.sAdxRRSource.interceptors.CustomPathInterceptor.datetimeFormatTimeZone = GMT+8

    # Describe the sink1
    odlSAdxRR.sinks.sAdxRRSink.type = hdfs
    odlSAdxRR.sinks.sAdxRRSink.hdfs.path = obs://hwsg-adx-backup-prod-01/odl/s-adx-rr/%{customPath}
    odlSAdxRR.sinks.sAdxRRSink.hdfs.filePrefix = ${MY_POD_NAME}
    odlSAdxRR.sinks.sAdxRRSink.hdfs.batchSize = 6000
    odlSAdxRR.sinks.sAdxRRSink.hdfs.rollTimerPoolSize=500
    odlSAdxRR.sinks.sAdxRRSink.hdfs.threadsPoolSize=2000
    odlSAdxRR.sinks.sAdxRRSink.hdfs.fileType = CompressedStream
    odlSAdxRR.sinks.sAdxRRSink.hdfs.minBlockReplicas = 1
    odlSAdxRR.sinks.sAdxRRSink.hdfs.codeC = bzip2
    odlSAdxRR.sinks.sAdxRRSink.hdfs.writeFormat = Text
    odlSAdxRR.sinks.sAdxRRSink.hdfs.round = true
    odlSAdxRR.sinks.sAdxRRSink.hdfs.roundValue = 1
    odlSAdxRR.sinks.sAdxRRSink.hdfs.roundUnit = second
    odlSAdxRR.sinks.sAdxRRSink.hdfs.idleTimeout=60
    odlSAdxRR.sinks.sAdxRRSink.hdfs.callTimeout=80000

    # rollSize = 1024Mb
    odlSAdxRR.sinks.sAdxRRSink.hdfs.rollSize = 1024000000
    odlSAdxRR.sinks.sAdxRRSink.hdfs.rollCount = 0
    odlSAdxRR.sinks.sAdxRRSink.hdfs.rollInterval = 600


    odlSAdxRR.channels.sAdxRRChannel.type = memory
    odlSAdxRR.channels.sAdxRRChannel.transactionCapacity = 2000000
    odlSAdxRR.channels.sAdxRRChannel.capacity = 100000000

    # Bind the source and sink to the channel
    odlSAdxRR.sources.sAdxRRSource.channels = sAdxRRChannel
    odlSAdxRR.sinks.sAdxRRSink.channel = sAdxRRChannel